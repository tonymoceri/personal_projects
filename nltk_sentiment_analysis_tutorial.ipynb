{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Experimentation with Starbucks Reviews. Trying to see if I can train a global dataset and apply it to my location, other locations in the district "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/freesurfer/SetUpFreeSurfer.csh: No such file or directory.\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tonymoceri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing nltk and ssl so that we can download some packages for a tutorial \n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download([\n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the state of the union corpus we just downloaded. Separating the words. str.isalpha() is to include only the words that are made up of letters\n",
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'TRUMAN',\n",
       " 'ADDRESS',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friends',\n",
       " 'colleagues',\n",
       " 'Congress',\n",
       " 'United',\n",
       " 'States',\n",
       " 'yesterday',\n",
       " 'laid',\n",
       " 'rest',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'time',\n",
       " 'like',\n",
       " 'words',\n",
       " 'inadequate',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'Yet',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'world',\n",
       " 'events',\n",
       " 'moving',\n",
       " 'rapidly',\n",
       " 'silence',\n",
       " 'might',\n",
       " 'misunderstood',\n",
       " 'might',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'enemies',\n",
       " 'infinite',\n",
       " 'wisdom',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'take',\n",
       " 'us',\n",
       " 'great',\n",
       " 'man',\n",
       " 'loved',\n",
       " 'beloved',\n",
       " 'humanity',\n",
       " 'man',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'fill',\n",
       " 'tremendous',\n",
       " 'void',\n",
       " 'left',\n",
       " 'passing',\n",
       " 'noble',\n",
       " 'soul',\n",
       " 'words',\n",
       " 'ease',\n",
       " 'aching',\n",
       " 'hearts',\n",
       " 'untold',\n",
       " 'millions',\n",
       " 'every',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'color',\n",
       " 'world',\n",
       " 'knows',\n",
       " 'lost',\n",
       " 'heroic',\n",
       " 'champion',\n",
       " 'justice',\n",
       " 'freedom',\n",
       " 'Tragic',\n",
       " 'fate',\n",
       " 'thrust',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'grave',\n",
       " 'responsibilities',\n",
       " 'must',\n",
       " 'carry',\n",
       " 'departed',\n",
       " 'leader',\n",
       " 'never',\n",
       " 'looked',\n",
       " 'backward',\n",
       " 'looked',\n",
       " 'forward',\n",
       " 'moved',\n",
       " 'forward',\n",
       " 'would',\n",
       " 'want',\n",
       " 'us',\n",
       " 'America',\n",
       " 'much',\n",
       " 'blood',\n",
       " 'already',\n",
       " 'shed',\n",
       " 'ideals',\n",
       " 'cherish',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'lived',\n",
       " 'died',\n",
       " 'dare',\n",
       " 'permit',\n",
       " 'even',\n",
       " 'momentary',\n",
       " 'pause',\n",
       " 'hard',\n",
       " 'fight',\n",
       " 'victory',\n",
       " 'Today',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'looking',\n",
       " 'America',\n",
       " 'enlightened',\n",
       " 'leadership',\n",
       " 'peace',\n",
       " 'progress',\n",
       " 'leadership',\n",
       " 'requires',\n",
       " 'vision',\n",
       " 'courage',\n",
       " 'tolerance',\n",
       " 'provided',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'deeply',\n",
       " 'devoted',\n",
       " 'highest',\n",
       " 'ideals',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'call',\n",
       " 'upon',\n",
       " 'Americans',\n",
       " 'help',\n",
       " 'keep',\n",
       " 'nation',\n",
       " 'united',\n",
       " 'defense',\n",
       " 'ideals',\n",
       " 'eloquently',\n",
       " 'proclaimed',\n",
       " 'Franklin',\n",
       " 'Roosevelt',\n",
       " 'want',\n",
       " 'turn',\n",
       " 'assure',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'liberty',\n",
       " 'throughout',\n",
       " 'world',\n",
       " 'support',\n",
       " 'defend',\n",
       " 'ideals',\n",
       " 'strength',\n",
       " 'heart',\n",
       " 'duty',\n",
       " 'shall',\n",
       " 'shirk',\n",
       " 'possible',\n",
       " 'misunderstanding',\n",
       " 'Germany',\n",
       " 'Japan',\n",
       " 'certain',\n",
       " 'beyond',\n",
       " 'shadow',\n",
       " 'doubt',\n",
       " 'America',\n",
       " 'continue',\n",
       " 'fight',\n",
       " 'freedom',\n",
       " 'vestige',\n",
       " 'resistance',\n",
       " 'remains',\n",
       " 'deeply',\n",
       " 'conscious',\n",
       " 'fact',\n",
       " 'much',\n",
       " 'hard',\n",
       " 'fighting',\n",
       " 'still',\n",
       " 'ahead',\n",
       " 'us',\n",
       " 'pay',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'make',\n",
       " 'complete',\n",
       " 'victory',\n",
       " 'certain',\n",
       " 'America',\n",
       " 'never',\n",
       " 'become',\n",
       " 'party',\n",
       " 'plan',\n",
       " 'partial',\n",
       " 'victory',\n",
       " 'settle',\n",
       " 'merely',\n",
       " 'another',\n",
       " 'temporary',\n",
       " 'respite',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'jeopardize',\n",
       " 'future',\n",
       " 'security',\n",
       " 'world',\n",
       " 'demand',\n",
       " 'remains',\n",
       " 'Unconditional',\n",
       " 'Surrender',\n",
       " 'traffic',\n",
       " 'breakers',\n",
       " 'peace',\n",
       " 'terms',\n",
       " 'peace',\n",
       " 'responsibility',\n",
       " 'making',\n",
       " 'peace',\n",
       " 'grave',\n",
       " 'responsibility',\n",
       " 'must',\n",
       " 'rest',\n",
       " 'defenders',\n",
       " 'peace',\n",
       " 'unconscious',\n",
       " 'dictates',\n",
       " 'humanity',\n",
       " 'wish',\n",
       " 'see',\n",
       " 'unnecessary',\n",
       " 'unjustified',\n",
       " 'suffering',\n",
       " 'laws',\n",
       " 'Go',\n",
       " 'man',\n",
       " 'violated',\n",
       " 'guilty',\n",
       " 'must',\n",
       " 'go',\n",
       " 'unpunished',\n",
       " 'Nothing',\n",
       " 'shall',\n",
       " 'shake',\n",
       " 'determination',\n",
       " 'punish',\n",
       " 'war',\n",
       " 'criminals',\n",
       " 'even',\n",
       " 'though',\n",
       " 'must',\n",
       " 'pursue',\n",
       " 'ends',\n",
       " 'earth',\n",
       " 'Lasting',\n",
       " 'peace',\n",
       " 'never',\n",
       " 'secured',\n",
       " 'permit',\n",
       " 'dangerous',\n",
       " 'opponents',\n",
       " 'plot',\n",
       " 'future',\n",
       " 'wars',\n",
       " 'impunity',\n",
       " 'mountain',\n",
       " 'retreat',\n",
       " 'however',\n",
       " 'distant',\n",
       " 'shrinking',\n",
       " 'world',\n",
       " 'futile',\n",
       " 'seek',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'geographical',\n",
       " 'barriers',\n",
       " 'Real',\n",
       " 'security',\n",
       " 'found',\n",
       " 'law',\n",
       " 'justice',\n",
       " 'America',\n",
       " 'labored',\n",
       " 'long',\n",
       " 'hard',\n",
       " 'achieve',\n",
       " 'social',\n",
       " 'order',\n",
       " 'worthy',\n",
       " 'great',\n",
       " 'heritage',\n",
       " 'time',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'made',\n",
       " 'toward',\n",
       " 'really',\n",
       " 'democratic',\n",
       " 'way',\n",
       " 'life',\n",
       " 'Let',\n",
       " 'assure',\n",
       " 'forward',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'America',\n",
       " 'w',\n",
       " 'ill',\n",
       " 'relaxation',\n",
       " 'efforts',\n",
       " 'improve',\n",
       " 'lot',\n",
       " 'common',\n",
       " 'people',\n",
       " 'difficult',\n",
       " 'days',\n",
       " 'ahead',\n",
       " 'unquestionably',\n",
       " 'shall',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'staggering',\n",
       " 'proportions',\n",
       " 'However',\n",
       " 'faith',\n",
       " 'fathers',\n",
       " 'hearts',\n",
       " 'fear',\n",
       " 'future',\n",
       " 'battlefields',\n",
       " 'frequently',\n",
       " 'faced',\n",
       " 'overwhelming',\n",
       " 'odds',\n",
       " 'home',\n",
       " 'Americans',\n",
       " 'less',\n",
       " 'resolute',\n",
       " 'shall',\n",
       " 'never',\n",
       " 'cease',\n",
       " 'struggle',\n",
       " 'preserve',\n",
       " 'maintain',\n",
       " 'American',\n",
       " 'way',\n",
       " 'life',\n",
       " 'moment',\n",
       " 'America',\n",
       " 'along',\n",
       " 'brave',\n",
       " 'Allies',\n",
       " 'paying',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'defense',\n",
       " 'freedom',\n",
       " 'characteristic',\n",
       " 'energy',\n",
       " 'assisting',\n",
       " 'liberation',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'Gradually',\n",
       " 'shackles',\n",
       " 'slavery',\n",
       " 'broken',\n",
       " 'forces',\n",
       " 'freedom',\n",
       " 'us',\n",
       " 'praying',\n",
       " 'speedy',\n",
       " 'victory',\n",
       " 'Every',\n",
       " 'day',\n",
       " 'peace',\n",
       " 'delayed',\n",
       " 'costs',\n",
       " 'terrible',\n",
       " 'toll',\n",
       " 'armies',\n",
       " 'liberation',\n",
       " 'today',\n",
       " 'bringing',\n",
       " 'end',\n",
       " 'Hitler',\n",
       " 'ghastly',\n",
       " 'threat',\n",
       " 'dominate',\n",
       " 'world',\n",
       " 'Tokyo',\n",
       " 'rocks',\n",
       " 'weight',\n",
       " 'bombs',\n",
       " 'grand',\n",
       " 'strategy',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'war',\n",
       " 'determined',\n",
       " 'due',\n",
       " 'small',\n",
       " 'measure',\n",
       " 'vision',\n",
       " 'departed',\n",
       " 'Commander',\n",
       " 'Chief',\n",
       " 'carrying',\n",
       " 'part',\n",
       " 'strategy',\n",
       " 'able',\n",
       " 'direction',\n",
       " 'Admiral',\n",
       " 'Leahy',\n",
       " 'General',\n",
       " 'Marshall',\n",
       " 'dmiral',\n",
       " 'King',\n",
       " 'General',\n",
       " 'Arnold',\n",
       " 'General',\n",
       " 'Eisenhower',\n",
       " 'Admiral',\n",
       " 'Nimitz',\n",
       " 'General',\n",
       " 'MacArthur',\n",
       " 'want',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'know',\n",
       " 'direction',\n",
       " 'must',\n",
       " 'remain',\n",
       " 'unchanged',\n",
       " 'unhampered',\n",
       " 'debt',\n",
       " 'heroic',\n",
       " 'men',\n",
       " 'valiant',\n",
       " 'women',\n",
       " 'service',\n",
       " 'country',\n",
       " 'never',\n",
       " 'repaid',\n",
       " 'earned',\n",
       " 'undying',\n",
       " 'gratitude',\n",
       " 'America',\n",
       " 'never',\n",
       " 'forget',\n",
       " 'sacrifices',\n",
       " 'sacrifices',\n",
       " 'dawn',\n",
       " 'justice',\n",
       " 'freedom',\n",
       " 'throughout',\n",
       " 'th',\n",
       " 'e',\n",
       " 'world',\n",
       " 'slowly',\n",
       " 'casts',\n",
       " 'gleam',\n",
       " 'across',\n",
       " 'horizon',\n",
       " 'forefathers',\n",
       " 'came',\n",
       " 'rugged',\n",
       " 'shores',\n",
       " 'search',\n",
       " 'religious',\n",
       " 'tolerance',\n",
       " 'political',\n",
       " 'freedom',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'risked',\n",
       " 'lives',\n",
       " 'well',\n",
       " 'know',\n",
       " 'today',\n",
       " 'rights',\n",
       " 'preserved',\n",
       " 'constant',\n",
       " 'vigilance',\n",
       " 'eternal',\n",
       " 'price',\n",
       " 'liberty',\n",
       " 'Within',\n",
       " 'hour',\n",
       " 'took',\n",
       " 'oath',\n",
       " 'office',\n",
       " 'announced',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'Conference',\n",
       " 'would',\n",
       " 'proceed',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'peace',\n",
       " 'courage',\n",
       " 'faced',\n",
       " 'mastered',\n",
       " 'problems',\n",
       " 'war',\n",
       " 'memory',\n",
       " 'made',\n",
       " 'supreme',\n",
       " 'sacrifice',\n",
       " 'memory',\n",
       " 'fallen',\n",
       " 'President',\n",
       " 'shall',\n",
       " 'fail',\n",
       " 'enough',\n",
       " 'yearn',\n",
       " 'peace',\n",
       " 'must',\n",
       " 'work',\n",
       " 'necessary',\n",
       " 'fight',\n",
       " 'task',\n",
       " 'creating',\n",
       " 'sound',\n",
       " 'international',\n",
       " 'organization',\n",
       " 'complicated',\n",
       " 'difficult',\n",
       " 'Yet',\n",
       " 'without',\n",
       " 'organization',\n",
       " 'rights',\n",
       " 'man',\n",
       " 'earth',\n",
       " 'cannot',\n",
       " 'protected',\n",
       " 'Machi',\n",
       " 'nery',\n",
       " 'settlement',\n",
       " 'international',\n",
       " 'differences',\n",
       " 'must',\n",
       " 'found',\n",
       " 'Without',\n",
       " 'machinery',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'remain',\n",
       " 'armed',\n",
       " 'camp',\n",
       " 'world',\n",
       " 'doomed',\n",
       " 'deadly',\n",
       " 'conflict',\n",
       " 'devoid',\n",
       " 'hope',\n",
       " 'real',\n",
       " 'peace',\n",
       " 'Fortunately',\n",
       " 'people',\n",
       " 'retained',\n",
       " 'hope',\n",
       " 'durable',\n",
       " 'peace',\n",
       " 'Thoughtful',\n",
       " 'people',\n",
       " 'always',\n",
       " 'faith',\n",
       " 'ultimately',\n",
       " 'justice',\n",
       " 'must',\n",
       " 'triumph',\n",
       " 'Past',\n",
       " 'experience',\n",
       " 'surely',\n",
       " 'indicates',\n",
       " 'without',\n",
       " 'justice',\n",
       " 'enduring',\n",
       " 'peace',\n",
       " 'becomes',\n",
       " 'impossible',\n",
       " 'bitter',\n",
       " 'despair',\n",
       " 'people',\n",
       " 'come',\n",
       " 'believe',\n",
       " 'wars',\n",
       " 'inevitable',\n",
       " 'tragic',\n",
       " 'fatalism',\n",
       " 'insist',\n",
       " 'wars',\n",
       " 'always',\n",
       " 'necessity',\n",
       " 'necessity',\n",
       " 'wars',\n",
       " 'always',\n",
       " 'defeatism',\n",
       " 'men',\n",
       " 'women',\n",
       " 'good',\n",
       " 'must',\n",
       " 'yield',\n",
       " 'outlook',\n",
       " 'humanity',\n",
       " 'hopeless',\n",
       " 'dark',\n",
       " 'hours',\n",
       " 'horrible',\n",
       " 'war',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'kept',\n",
       " 'going',\n",
       " 'something',\n",
       " 'intangible',\n",
       " 'hope',\n",
       " 'warned',\n",
       " 'abject',\n",
       " 'submission',\n",
       " 'offered',\n",
       " 'salvation',\n",
       " 'overwhelming',\n",
       " 'power',\n",
       " 'hope',\n",
       " 'showed',\n",
       " 'way',\n",
       " 'victory',\n",
       " 'Hope',\n",
       " 'become',\n",
       " 'secret',\n",
       " 'weapon',\n",
       " 'forces',\n",
       " 'liberation',\n",
       " 'Aggressors',\n",
       " 'could',\n",
       " 'dominate',\n",
       " 'human',\n",
       " 'mind',\n",
       " 'long',\n",
       " 'hope',\n",
       " 'remains',\n",
       " 'spirit',\n",
       " 'man',\n",
       " 'never',\n",
       " 'crushed',\n",
       " 'hope',\n",
       " 'alone',\n",
       " 'sufficient',\n",
       " 'avert',\n",
       " 'war',\n",
       " 'must',\n",
       " 'hope',\n",
       " 'must',\n",
       " 'faith',\n",
       " 'enough',\n",
       " 'work',\n",
       " 'peace',\n",
       " 'loving',\n",
       " 'nations',\n",
       " 'maintain',\n",
       " 'peace',\n",
       " 'Hope',\n",
       " 'enough',\n",
       " 'beat',\n",
       " 'back',\n",
       " 'aggressors',\n",
       " 'long',\n",
       " 'peace',\n",
       " 'loving',\n",
       " 'nations',\n",
       " 'unwilling',\n",
       " 'come',\n",
       " 'defense',\n",
       " 'aggressors',\n",
       " 'beaten',\n",
       " 'back',\n",
       " 'peace',\n",
       " 'loving',\n",
       " 'nations',\n",
       " 'united',\n",
       " 'defend',\n",
       " 'wars',\n",
       " 'future',\n",
       " 'prevented',\n",
       " 'nations',\n",
       " 'must',\n",
       " 'united',\n",
       " 'determination',\n",
       " 'keep',\n",
       " 'peace',\n",
       " 'law',\n",
       " 'Nothing',\n",
       " 'essential',\n",
       " 'future',\n",
       " 'peace',\n",
       " 'world',\n",
       " 'continued',\n",
       " 'cooperation',\n",
       " 'nations',\n",
       " 'muster',\n",
       " 'force',\n",
       " 'necessary',\n",
       " 'defeat',\n",
       " 'conspiracy',\n",
       " 'Axis',\n",
       " 'powers',\n",
       " 'dominate',\n",
       " 'world',\n",
       " 'great',\n",
       " 'states',\n",
       " 'special',\n",
       " 'responsibility',\n",
       " 'enforce',\n",
       " 'peace',\n",
       " 'responsibility',\n",
       " 'based',\n",
       " 'upon',\n",
       " 'obligations',\n",
       " 'resting',\n",
       " 'upon',\n",
       " 'states',\n",
       " 'large',\n",
       " 'small',\n",
       " 'use',\n",
       " 'force',\n",
       " 'international',\n",
       " 'relations',\n",
       " 'except',\n",
       " 'defense',\n",
       " 'law',\n",
       " 'respon',\n",
       " 'sibility',\n",
       " 'great',\n",
       " 'states',\n",
       " 'serve',\n",
       " 'dominate',\n",
       " 'world',\n",
       " 'build',\n",
       " 'foundation',\n",
       " 'enduring',\n",
       " 'peace',\n",
       " 'must',\n",
       " 'work',\n",
       " 'harmony',\n",
       " 'friends',\n",
       " 'abroad',\n",
       " 'must',\n",
       " 'united',\n",
       " 'support',\n",
       " 'people',\n",
       " 'Even',\n",
       " 'experienced',\n",
       " 'pilot',\n",
       " 'cannot',\n",
       " 'bring',\n",
       " 'ship',\n",
       " 'safely',\n",
       " 'harbor',\n",
       " 'unless',\n",
       " 'full',\n",
       " 'cooperation',\n",
       " 'crew',\n",
       " 'benefit',\n",
       " 'every',\n",
       " 'individual',\n",
       " 'must',\n",
       " 'duty',\n",
       " 'appeal',\n",
       " 'every',\n",
       " 'American',\n",
       " 'regardless',\n",
       " 'party',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'color',\n",
       " 'support',\n",
       " 'efforts',\n",
       " 'build',\n",
       " 'strong',\n",
       " 'lasting',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'Organization',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'surely',\n",
       " 'know',\n",
       " 'feel',\n",
       " 'help',\n",
       " 'hope',\n",
       " 'complete',\n",
       " 'one',\n",
       " 'greatest',\n",
       " 'tasks',\n",
       " 'ever',\n",
       " 'assigned',\n",
       " 'public',\n",
       " 'servant',\n",
       " 'Divine',\n",
       " 'guidance',\n",
       " 'help',\n",
       " 'find',\n",
       " 'new',\n",
       " 'passage',\n",
       " 'far',\n",
       " 'better',\n",
       " 'world',\n",
       " 'kindly',\n",
       " 'friendly',\n",
       " 'world',\n",
       " 'lasting',\n",
       " 'peace',\n",
       " 'confidence',\n",
       " 'depending',\n",
       " 'upon',\n",
       " 'destroy',\n",
       " 'greedy',\n",
       " 'tyrants',\n",
       " 'dreams',\n",
       " 'world',\n",
       " 'domination',\n",
       " 'cannot',\n",
       " 'continue',\n",
       " 'successive',\n",
       " 'generations',\n",
       " 'sacrifice',\n",
       " 'finest',\n",
       " 'youth',\n",
       " 'name',\n",
       " 'human',\n",
       " 'decency',\n",
       " 'civilization',\n",
       " 'rational',\n",
       " 'method',\n",
       " 'deciding',\n",
       " 'national',\n",
       " 'differences',\n",
       " 'must',\n",
       " 'found',\n",
       " 'America',\n",
       " 'must',\n",
       " 'assist',\n",
       " 'suffering',\n",
       " 'humanity',\n",
       " 'back',\n",
       " 'along',\n",
       " 'path',\n",
       " 'peaceful',\n",
       " 'progress',\n",
       " 'require',\n",
       " 'time',\n",
       " 'tolerance',\n",
       " 'shall',\n",
       " 'need',\n",
       " 'also',\n",
       " 'abiding',\n",
       " 'faith',\n",
       " 'people',\n",
       " 'kind',\n",
       " 'faith',\n",
       " 'courage',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'always',\n",
       " 'Today',\n",
       " 'America',\n",
       " 'become',\n",
       " 'one',\n",
       " 'powerful',\n",
       " 'forces',\n",
       " 'good',\n",
       " 'earth',\n",
       " 'must',\n",
       " 'keep',\n",
       " 'achieved',\n",
       " 'world',\n",
       " 'leadership',\n",
       " 'depend',\n",
       " 'solely',\n",
       " 'upon',\n",
       " 'military',\n",
       " 'naval',\n",
       " 'might',\n",
       " 'learned',\n",
       " 'fight',\n",
       " 'nations',\n",
       " 'common',\n",
       " 'defense',\n",
       " 'freedom',\n",
       " 'must',\n",
       " 'learn',\n",
       " 'live',\n",
       " 'nations',\n",
       " 'mutual',\n",
       " 'good',\n",
       " 'must',\n",
       " 'learn',\n",
       " 'trade',\n",
       " 'nations',\n",
       " 'may',\n",
       " 'mutual',\n",
       " 'advantage',\n",
       " 'increased',\n",
       " 'product',\n",
       " 'ion',\n",
       " 'increased',\n",
       " 'employment',\n",
       " 'better',\n",
       " 'standards',\n",
       " 'living',\n",
       " 'throughout',\n",
       " 'world',\n",
       " 'May',\n",
       " 'Americans',\n",
       " 'live',\n",
       " 'glorious',\n",
       " 'heritage',\n",
       " 'way',\n",
       " 'America',\n",
       " 'may',\n",
       " 'well',\n",
       " 'lead',\n",
       " 'world',\n",
       " 'peace',\n",
       " 'prosperity',\n",
       " 'moment',\n",
       " 'heart',\n",
       " 'prayer',\n",
       " 'assumed',\n",
       " 'heavy',\n",
       " 'duties',\n",
       " 'humbly',\n",
       " 'pray',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'words',\n",
       " 'King',\n",
       " 'Solomon',\n",
       " 'Give',\n",
       " 'therefore',\n",
       " 'thy',\n",
       " 'servant',\n",
       " 'understanding',\n",
       " 'heart',\n",
       " 'judge',\n",
       " 'thy',\n",
       " 'people',\n",
       " 'may',\n",
       " 'discern',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'able',\n",
       " 'judge',\n",
       " 'thy',\n",
       " 'great',\n",
       " 'people',\n",
       " 'ask',\n",
       " 'good',\n",
       " 'faithful',\n",
       " 'servant',\n",
       " 'Lord',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common words such as \"a\", \"the\", \"of\", etc. are referred to as \"stopwords\". NLTK can essentially remove/ignore these words using a function called .stopwords... \n",
    "# Because the corpus contains stopwords in multiple languages, we want to include the \"english\" argument here\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Now, we can remove the stopwords from our words variable and limit the scope of the corpus a bit... \n",
    "words = [w for w in words if w.lower() not in stopwords]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since asll words in the stopwords list are lowercase, and those in the original list may not be, you can use str.lower() to account for any discrpencies. Otherwise you may end up with mixed case or capitalized stop words still in your list\n",
    "\n",
    "It is possible to build your own text corpora from any source. Building a corpus can be as simple as loading some plain text or as complex as labeling and categorizing each sentence. We can find NLTK's documentation on how to work with corpus readers. \n",
    "\n",
    "For this tutorial, we are just going to use the built-in corpora provided by NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
      " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
      " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK provides nltk.word_tokenize(), a function that splits raw text into individual words. This will deliver simple word lists really well. \n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "text = \"\"\"\n",
    "For some quick analysis, creating a corpus could be overkill.\n",
    "If all you need is a word list,\n",
    "there are simpler ways to achieve that goal.\"\"\"\n",
    "\n",
    "pprint(nltk.word_tokenize(text), width=79, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Frequency Distributions \n",
    "\n",
    "A frequency distribution is essentially a table that tells you how many times each word appears within a given text. In NLTK, frequency distributions are a specific object type implementend as a distinct class called \"FreqDist\". This class provides useful operations for word frequency analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words: list[str] = nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)\n",
    "\n",
    "# This will create a frequency distribution object similar to a Python dictionary but with added features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 2), ('a', 2), ('.', 2)]\n",
      ", a . \n",
      "2 2 2 \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# After building the object, we can use methods like .most_common() and .tabulate() to start visualizing information: \n",
    "print(fd.most_common(3))\n",
    "print(fd.tabulate(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Concordance and Collocations \n",
    "In the context of NLP, a __concordance__ is a collection of word locations along with their context. You can use these to find: \n",
    "1. How many times a word appears \n",
    "2. Where each occurrence appears \n",
    "3. What words surround each occurrence \n",
    "\n",
    "In NLTK, you can do this by calling .concordance(). To use it, you need an unstance of the nltk.Text class, which can also be constructed with a word list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "# Before invoking .concordance(), build a new word list from the original corpus text so that all the context, even stop words, will be there\n",
    "text = nltk.Text(nltk.corpus.state_union.words())\n",
    "text.concordance(\"america\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# To obtain a usable list that will also give you information about the location of each occurrence, use .concordance_list(): \n",
    "\n",
    "concordance_list = text.concordance_list(\"america\", lines=2)\n",
    "for entry in concordance_list:\n",
    "    print(entry.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    is better   than \n",
      "     3      3      3 \n"
     ]
    }
   ],
   "source": [
    "# Revisiting nltk.word_tokenize(), check out how quickly you can create a custom nltk.Text instance and an accompanying frequency distribution: \n",
    "words: list[str] = nltk.word_tokenize(\n",
    "    \"\"\"Beautiful is better than ugly. \n",
    "    Explicit is better than implicit.\n",
    "    Simple is better than complex.\"\"\"\n",
    ")\n",
    "text = nltk.Text(words)\n",
    "fd = text.vocab()\n",
    "fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another powerful feature of NLTK is its ability to quickly find __collocations__ with simmple function calls. Collocations are series of words that frequently appear together in a given text. In the State of the Union corpus, for example, you'd expect to find the words _United_ and _States_ appearing next to each other very often. Those two words appearing together is a collocation. \n",
    "\n",
    "Collocations can be made up of two or more words. NLTK provides classes to handle several types of collocations: \n",
    "- __Bigrams:__ Frequent two-word combinations \n",
    "- __Trigrams:__ Frequent three-word combinations\n",
    "- __Quadgrams:__ Frequent four-word combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of their most useful tools is the `ngram_fd` property. This property holds a frequency distribution that is build for each collocation rather than for individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ('the', 'United', 'States') ('the', 'American', 'people') \n",
      "                          294                           185 \n"
     ]
    }
   ],
   "source": [
    "# Using ngram_fd, we can find the most common collocations in this supplied text:\n",
    "finder.ngram_fd.most_common(2)\n",
    "finder.ngram_fd.tabulate(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK's Pre-Trained Sentiment Analyzer \n",
    "\n",
    "NLTK already has a built-in, pretrained sentiment analyzer called VADER (__V__alence __A__ware __D__ictionary and s__E__ntiment __R__easoner). \n",
    "\n",
    "Since VADER is pretrained, you can get results more quickly then with many other analyzers. However, VADER is best suited for language used in social media, like short sentences with some slang and abbreviations. It's less accurate when rating longer, structured sentences, but it's often a good launching point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use VADER, first create an instance of nltk.sentiment.SentimentIntensityAnalyzer, then use .polarity_scores() on a raw string:\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer \n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a dictionary of different scores. The negative, neutral, and positive scores are related: they all add up to 1 and cannot be negative. The compound score is calculated differently. It is not just and average, and it can range from -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the twitter_samples corpus into a list of strings, making a replacement to render URLs inactive to avoid accidental clicks:\n",
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False RT @Number10cat: In the usual #bbcqt slot the BBC is showing 30 minutes of just Nigel Farage; not sure I'll be able to tell the difference.…\n",
      "> False RT @DVATW: Off to the #foodbank to fight off the hunger caused by evil Tory cuts... http//t.co/zjfy2Cq6zg\n",
      "> False RT @serialsockthief: When Labour decided to side with Tories in September, they hurt Scotland. This time they'll hurt the whole of the UK. …\n",
      "> False RT @andy2heart: watching nigel farage who speaks a lot nore sense than many other politicians he knows his facts and speaks a lot of sense\n",
      "> False @Ed_Miliband What do you don if you're say 40 seats short of a majority and SNP can offer those seats?\n",
      "> True RT @BurpTv: Now a vote for UKIP IS NOT A WASTED  VOTE!!!!\n",
      "> True RT @MaggieBakesBuns: @Ed_Miliband you've won me over after a prolonged period of uncertainty. Please get rid of this Tory government.\n",
      "> False RT @UKIP: #UKIP Leader @Nigel_Farage on UKIP's pledge for £3bn more for our #NHS #AskNigelFarage #bbcqt http//t.co/ehaWkQl28R\n",
      "> True RT @AngusMacNeilSNP: @DavidPBMaddox Miliband has written his resignation letter ... next Lab leader will deal with SNP #simple :)\n",
      "> True LOOKING FOR GEN.AD. BETTER IF THE PRICE CAN BE NEGOTIABLE :(((( CAN SOMEONE HELP ME :((((( , HUHUHUHUHU #BBMADEinManila  #FindaVIP\n"
     ]
    }
   ],
   "source": [
    "# Now, let's use the .polarity_scores() function of your SentimentIntensityAnalyzer instance to classify tweets:\n",
    "\n",
    "from random import shuffle\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, is_positive() uses only the positivity of the compound score to make the call. You can choose any combination of VADER scores to tweak the classification to your needs. \n",
    "\n",
    "Now take a look at the second corpus, movie_reviews. The special thing about this corpus is that it's already been classified. Therefore, you can use it to judge the accuracy of the algorithms you choose when rating similar texts. \n",
    "\n",
    "Keep in mind that VADER is likely better at rating tweets than it is at rating long movie reviews. To get better results, you'll set up VADER to rate individual sentences within the review rather than the entire text. \n",
    "\n",
    "Since VADER needs raw strings for its rating, you can't use .words() like you did earlier. Instead, make a list of the file IDs that the corpus uses, which you can use later to reference individual reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def is_positive(review_id: str) -> bool: \n",
    "    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.00% correct\n"
     ]
    }
   ],
   "source": [
    "shuffle(all_review_ids)\n",
    "correct = 0\n",
    "for review_id in all_review_ids:\n",
    "    if is_positive(review_id):\n",
    "        if review_id in positive_review_ids:\n",
    "            correct += 1\n",
    "    else:\n",
    "        if review_id in negative_review_ids:\n",
    "            correct += 1\n",
    "print(F\"{correct / len(all_review_ids):.2%} correct\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing NLTK's Sentimient Analysis\n",
    "NLTK offers a few built-in classifiers that are suitable for various types of analyses, including sentiment analysis. The trick is to figure out which properties of your dataset are useful in classifying each piece of data into your desire categories. \n",
    "\n",
    "In the world of machine learning, these data properties are known as __features__, which you must reveal and select as you work with your data.\n",
    "\n",
    "## Selecting Useful Features \n",
    "By using predefined categories in the movie_review corpus, you can create sets of positive and negative words, then determine which ones occur most frequently across each set. Begin by excluding unwanted workds and building the initial category groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted: \n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])\n",
    "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
    "    if w.isalpha() and w not in unwanted \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
